{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question answering using a search API and re-ranking\n",
    "\n",
    "Searching for relevant information can sometimes feel like looking for a needle in a haystack, but don’t despair, GPTs can actually do a lot of this work for us. In this guide we explore a way to augment existing search systems with various AI techniques, helping us sift through the noise.\n",
    "\n",
    "Two ways of retrieving information for GPT are:\n",
    "\n",
    "1. **Mimicking Human Browsing:** [GPT triggers a search](https://openai.com/blog/chatgpt-plugins#browsing), evaluates the results, and modifies the search query if necessary. It can also follow up on specific search results to form a chain of thought, much like a human user would do.\n",
    "2. **Retrieval with Embeddings:** Calculate [embeddings](https://platform.openai.com/docs/guides/embeddings) for your content and a user query, and then [retrieve the content](Question_answering_using_embeddings.ipynb) most related as measured by cosine similarity. This technique is [used heavily](https://blog.google/products/search/search-language-understanding-bert/) by search engines like Google.\n",
    "\n",
    "These approaches are both promising, but each has their shortcomings: the first one can be slow due to its iterative nature and the second one requires embedding your entire knowledge base in advance, continuously embedding new content and maintaining a vector database.\n",
    "\n",
    "By combining these approaches, and drawing inspiration from [re-ranking](https://www.sbert.net/examples/applications/retrieve_rerank/README.html) methods, we identify an approach that sits in the middle. **This approach can be implemented on top of any existing search system, like the Slack search API, or an internal ElasticSearch instance with private data**. Here’s how it works:\n",
    "\n",
    "![search_augmented_by_query_generation_and_embeddings_reranking.png](../images/search_rerank_answer.png)\n",
    "\n",
    "**Step 1: Search**\n",
    "\n",
    "1.  User asks a question.\n",
    "2.  GPT generates a list of potential queries.\n",
    "3.  Search queries are executed in parallel.\n",
    "\n",
    "**Step 2: Re-rank**\n",
    "\n",
    "1.  Embeddings for each result are used to calculate semantic similarity to a generated hypothetical ideal answer to the user question.\n",
    "2.  Results are ranked and filtered based on this similarity metric.\n",
    "\n",
    "**Step 3: Answer**\n",
    "\n",
    "1.  Given the top search results, the model generates an answer to the user’s question, including references and links.\n",
    "\n",
    "This hybrid approach offers relatively low latency and can be integrated into any existing search endpoint, without requiring the upkeep of a vector database. Let's dive into it! We will use the [News API](https://newsapi.org/) as an example domain to search over.\n",
    "\n",
    "## Setup\n",
    "\n",
    "In addition to your `OPENAI_API_KEY`, you'll have to include a `NEWS_API_KEY` in your environment. You can get an API key [here](https://newsapi.org/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'openai' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m load_dotenv()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m openai\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m news_api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m\"\u001b[39m\u001b[39mNEWS_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'openai' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "from datetime import date, timedelta  # date handling for fetching recent news\n",
    "from IPython import display  # for pretty printing\n",
    "import json  # for parsing the JSON api responses and model outputs\n",
    "from numpy import dot  # for cosine similarity\n",
    "import openai  # for using GPT and getting embeddings\n",
    "import os  # for loading environment variables\n",
    "import requests  # for making the API requests\n",
    "from tqdm.notebook import tqdm  # for printing progress bars\n",
    "\n",
    "# Load environment variables\n",
    "\n",
    "\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def json_gpt(input: str):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=GPT_MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Output only valid JSON\"},\n",
    "            {\"role\": \"user\", \"content\": input},\n",
    "        ],\n",
    "        temperature=0.5,\n",
    "    )\n",
    "\n",
    "    text = completion.choices[0].message.content\n",
    "    parsed = json.loads(text)\n",
    "\n",
    "    return parsed\n",
    "\n",
    "\n",
    "def embeddings(input): \n",
    "    response = openai.Embedding.create(model=\"text-embedding-ada-002\", input=input)\n",
    "    return [data.embedding for data in response.data]\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "news_api_key = os.getenv(\"NEWS_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Search\n",
    "\n",
    "It all starts with a user question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good afternoon, everyone. And welcome to FinTech Plus Sync's second quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a stellar second quarter (Q2) with a revenue of $125 million, a 25% increase year over year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our Earnings Before Interest, Taxes, Depreciation, and Amortization (EBITDA) has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially thanks to the expansion of our high yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in Collateralized Debt Obligations (CDOs), and Residential Mortgage-Backed Securities (RMBS). We've also invested $25 million in AAA rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with Customer Acquisition Cost (CAC) dropping by 15% and Lifetime Value (LTV) growing by 25%. Our LTV to CAC (LTVCAC) ratio is at an impressive 3.5%. In terms of risk management, we have a Value at Risk (VaR) model in place with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage and have a healthy Tier 1 Capital Ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million and 8% quarter over quarter growth driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming Initial Public Offering (IPO) of our FinTech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us and we look forward to an even more successful third quarter (Q3). Thank you so much.\n",
      "\n",
      "Words changed: \n",
      "Q2 to second quarter (Q2)\n",
      "EBITDA to Earnings Before Interest, Taxes, Depreciation, and Amortization (EBITDA)\n",
      "CDOs to Collateralized Debt Obligations (CDOs)\n",
      "RMBS to Residential Mortgage-Backed Securities (RMBS)\n",
      "CAC to Customer Acquisition Cost (CAC)\n",
      "LTV to Lifetime Value (LTV)\n",
      "LTVCAC to LTV to CAC (LTVCAC)\n",
      "VaR to Value at Risk (VaR)\n",
      "IPO to Initial Public Offering (IPO)\n",
      "Q3 to third quarter (Q3)\n"
     ]
    }
   ],
   "source": [
    "# User asks a question\n",
    "# load the question\n",
    "file_path = \"data/final_transcript.txt\"\n",
    "with open(file_path, \"r\") as f:\n",
    "    final_transcript = f.read()\n",
    "USER_QUESTION = final_transcript\n",
    "print(USER_QUESTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in order to be as exhaustive as possible, we use the model to generate a list of diverse queries based on this question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FinTech Plus Sync second quarter 2023 earnings call',\n",
       " 'FinTech Plus Q2 revenue',\n",
       " 'FinTech Plus Q2 gross profit margin',\n",
       " 'FinTech Plus Q2 EBITDA',\n",
       " 'FinTech Plus Q2 net income',\n",
       " 'FinTech Plus high yield savings product line expansion',\n",
       " 'FinTech Plus RoboAdvisor platform',\n",
       " 'FinTech Plus asset-backed securities portfolio diversification',\n",
       " 'FinTech Plus CDOs investment',\n",
       " 'FinTech Plus RMBS investment',\n",
       " 'FinTech Plus corporate bonds investment',\n",
       " 'FinTech Plus balance sheet',\n",
       " 'FinTech Plus debt-to-equity ratio',\n",
       " 'FinTech Plus organic user growth',\n",
       " 'FinTech Plus CAC',\n",
       " 'FinTech Plus LTV',\n",
       " 'FinTech Plus LTVCAC ratio',\n",
       " 'FinTech Plus risk management',\n",
       " 'FinTech Plus VaR model',\n",
       " 'FinTech Plus Tier 1 Capital Ratio',\n",
       " 'FinTech Plus Q3 forecast',\n",
       " 'FinTech Plus blockchain solutions',\n",
       " 'FinTech Plus AI-driven predictive analytics',\n",
       " 'FinTech Plus IPO',\n",
       " 'FinTech Plus Q3 expectations',\n",
       " \"Good afternoon, everyone. And welcome to FinTech Plus Sync's second quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a stellar second quarter (Q2) with a revenue of $125 million, a 25% increase year over year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our Earnings Before Interest, Taxes, Depreciation, and Amortization (EBITDA) has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially thanks to the expansion of our high yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in Collateralized Debt Obligations (CDOs), and Residential Mortgage-Backed Securities (RMBS). We've also invested $25 million in AAA rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with Customer Acquisition Cost (CAC) dropping by 15% and Lifetime Value (LTV) growing by 25%. Our LTV to CAC (LTVCAC) ratio is at an impressive 3.5%. In terms of risk management, we have a Value at Risk (VaR) model in place with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage and have a healthy Tier 1 Capital Ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million and 8% quarter over quarter growth driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming Initial Public Offering (IPO) of our FinTech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us and we look forward to an even more successful third quarter (Q3). Thank you so much.\\n\\nWords changed: \\nQ2 to second quarter (Q2)\\nEBITDA to Earnings Before Interest, Taxes, Depreciation, and Amortization (EBITDA)\\nCDOs to Collateralized Debt Obligations (CDOs)\\nRMBS to Residential Mortgage-Backed Securities (RMBS)\\nCAC to Customer Acquisition Cost (CAC)\\nLTV to Lifetime Value (LTV)\\nLTVCAC to LTV to CAC (LTVCAC)\\nVaR to Value at Risk (VaR)\\nIPO to Initial Public Offering (IPO)\\nQ3 to third quarter (Q3)\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "QUERIES_INPUT = f\"\"\"\n",
    "You have access to a search API that returns recent news articles.\n",
    "Generate an array of search queries that are relevant to this question.\n",
    "Use a variation of related keywords for the queries, trying to be as general as possible.\n",
    "Include as many queries as you can think of, including and excluding terms.\n",
    "For example, include queries like ['keyword_1 keyword_2', 'keyword_1', 'keyword_2'].\n",
    "Be creative. The more queries you include, the more likely you are to find relevant results.\n",
    "\n",
    "User question: {USER_QUESTION}\n",
    "\n",
    "Format: {{\"queries\": [\"query_1\", \"query_2\", \"query_3\"]}}\n",
    "\"\"\"\n",
    "\n",
    "queries = json_gpt(QUERIES_INPUT)[\"queries\"]\n",
    "\n",
    "# Let's include the original question as well for good measure\n",
    "queries.append(USER_QUESTION)\n",
    "\n",
    "queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The queries look good, so let's run the searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fa113119084325902fc28bd3aa1303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of articles: 51\n",
      "Top 5 articles of query 1: \n",
      "\n",
      "Title: Edgio, Inc. (NASDAQ:EGIO) Q2 2023 Earnings Call Transcript\n",
      "Description: Edgio, Inc. (NASDAQ:EGIO) Q2 2023 Earnings Call Transcript September 12, 2023 Edgio, Inc. misses on earnings expectations. Reported EPS is $-0.12 EPS...\n",
      "Content: Edgio, Inc. (NASDAQ:EGIO) Q2 2023 Earnings Call Transcript September 12, 2023\n",
      "Edgio, Inc. misses on...\n",
      "\n",
      "Title: IBEX Limited (NASDAQ:IBEX) Q4 2023 Earnings Call Transcript\n",
      "Description: IBEX Limited (NASDAQ:IBEX) Q4 2023 Earnings Call Transcript September 13, 2023 IBEX Limited misses on earnings expectations. Reported EPS is $0.33 EPS...\n",
      "Content: IBEX Limited (NASDAQ:IBEX) Q4 2023 Earnings Call Transcript September 13, 2023\n",
      "IBEX Limited misses ...\n",
      "\n",
      "Title: Marketing for Coaches: How to Win Coaching Clients + Real-Life Hints from Coaching Experts\n",
      "Description: OK, you already defined your coaching niche and your target audience. You also checked off arranging your coaching services into clear packages and pricing.  So, the game begins. You are ready to market your coaching business and attract your ideal clients. B…\n",
      "Content: OK, you already defined your coaching niche and your target audience. You also checked off arranging...\n",
      "\n",
      "Title: Share Market Highlights 06 October 2023: Sensex up 364 pts, Nifty closes above 19,650; TCS to consider share buyback next week\n",
      "Description: Sensex, Nifty updates on 06 October 2023: Indian shares advanced on Friday, led by gains in rate-sensitive sectors like auto, financials and realty, after the RBI kept key interest rates steady, as expected, and maintained its growth forecasts. The NSE Nifty …\n",
      "Content: <li></li>\n",
      "October 06, 2023 16:47Rupee rises 4 paise to close at 83.21 against US dollar\n",
      "The rupee ...\n",
      "\n",
      "Title: Share Market Highlights 10 October 2023: Sensex gains 567 pts; Nifty around 19,700; Coal India jumps 5%\n",
      "Description: Sensex, Nifty updates on 10 October 2023 – The Sensex surged by 566.97 points or 0.87 percent to reach 66,079.36, while the Nifty gained 177.50 points or 0.91 percent, closing at 19,689.80. Notably, the realty sector led the gains with a 4 per cent rise, whil…\n",
      "Content: <li></li>\n",
      "October 10, 2023 16:27Sensex, Nifty rebound up to 1% on gains in financial, auto shares\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def search_news(\n",
    "    query: str,\n",
    "    news_api_key: str = news_api_key,\n",
    "    num_articles: int = 50,\n",
    "    from_datetime: str = \"2023-09-12\",  # the 2023 NBA finals were played in June 2023\n",
    "    to_datetime: str = \"2023-10-11\",\n",
    ") -> dict:\n",
    "    response = requests.get(\n",
    "        \"https://newsapi.org/v2/everything\",\n",
    "        params={\n",
    "            \"q\": query,\n",
    "            \"apiKey\": news_api_key,\n",
    "            \"pageSize\": num_articles,\n",
    "            \"sortBy\": \"relevancy\",\n",
    "            \"from\": from_datetime,\n",
    "            \"to\": to_datetime,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "articles = []\n",
    "\n",
    "for query in tqdm(queries):\n",
    "    if len(query) > 499:\n",
    "        continue\n",
    "    result = search_news(query)\n",
    "    if result[\"status\"] == \"ok\":\n",
    "        articles = articles + result[\"articles\"]\n",
    "    else:\n",
    "        raise Exception(result[\"message\"])\n",
    "\n",
    "# remove duplicates\n",
    "articles = list({article[\"url\"]: article for article in articles}.values())\n",
    "\n",
    "print(\"Total number of articles:\", len(articles))\n",
    "print(\"Top 5 articles of query 1:\", \"\\n\")\n",
    "\n",
    "for article in articles[0:5]:\n",
    "    print(\"Title:\", article[\"title\"])\n",
    "    print(\"Description:\", article[\"description\"])\n",
    "    print(\"Content:\", article[\"content\"][0:100] + \"...\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, oftentimes, the search queries will return a large number of results, many of which are not relevant to the original question asked by the user. In order to improve the quality of the final answer, we use embeddings to re-rank and filter the results.\n",
    "\n",
    "## 2. Re-rank\n",
    "\n",
    "Drawing inspiration from [HyDE (Gao et al.)](https://arxiv.org/abs/2212.10496), we first generate a hypothetical ideal answer to rerank our compare our results against. This helps prioritize results that look like good answers, rather than those similar to our question. Here’s the prompt we use to generate our hypothetical answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Good afternoon, everyone. And welcome to FinTech Plus Sync's second quarter 2023 earnings call. I'm John Doe, CEO of FinTech Plus. We've had a remarkable second quarter (Q2) with a revenue of $125 million, a 25% increase year over year. Our gross profit margin stands at a solid 58%, due in part to cost efficiencies gained from our scalable business model. Our Earnings Before Interest, Taxes, Depreciation, and Amortization (EBITDA) has surged to $37.5 million, translating to a remarkable 30% EBITDA margin. Our net income for the quarter rose to $16 million, which is a noteworthy increase from $10 million in Q2 2022. Our total addressable market has grown substantially thanks to the expansion of our high yield savings product line and the new RoboAdvisor platform. We've been diversifying our asset-backed securities portfolio, investing heavily in Collateralized Debt Obligations (CDOs), and Residential Mortgage-Backed Securities (RMBS). We've also invested $25 million in AAA rated corporate bonds, enhancing our risk-adjusted returns. As for our balance sheet, total assets reached $1.5 billion with total liabilities at $900 million, leaving us with a solid equity base of $600 million. Our debt-to-equity ratio stands at 1.5, a healthy figure considering our expansionary phase. We continue to see substantial organic user growth, with Customer Acquisition Cost (CAC) dropping by 15% and Lifetime Value (LTV) growing by 25%. Our LTV to CAC (LTVCAC) ratio is at an impressive 3.5%. In terms of risk management, we have a Value at Risk (VaR) model in place with a 99% confidence level indicating that our maximum loss will not exceed $5 million in the next trading day. We've adopted a conservative approach to managing our leverage and have a healthy Tier 1 Capital Ratio of 12.5%. Our forecast for the coming quarter is positive. We expect revenue to be around $135 million and 8% quarter over quarter growth driven primarily by our cutting-edge blockchain solutions and AI-driven predictive analytics. We're also excited about the upcoming Initial Public Offering (IPO) of our FinTech subsidiary, Pay Plus, which we expect to raise $200 million, significantly bolstering our liquidity and paving the way for aggressive growth strategies. We thank our shareholders for their continued faith in us and we look forward to an even more successful third quarter (Q3). Thank you so much.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HA_INPUT = f\"\"\"\n",
    "Generate a hypothetical answer to the user's question. This answer will be used to rank search results. \n",
    "Pretend you have all the information you need to answer, but don't use any actual facts. Instead, use placeholders\n",
    "like NAME did something, or NAME said something at PLACE. \n",
    "\n",
    "User question: {USER_QUESTION}\n",
    "\n",
    "Format: {{\"hypotheticalAnswer\": \"hypothetical answer text\"}}\n",
    "\"\"\"\n",
    "\n",
    "hypothetical_answer = json_gpt(HA_INPUT)[\"hypotheticalAnswer\"]\n",
    "\n",
    "hypothetical_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's generate embeddings for the search results and the hypothetical answer. We then calculate the cosine distance between these embeddings, giving us a semantic similarity metric. Note that we can simply calculate the dot product in lieu of doing a full cosine similarity calculation since the OpenAI embeddings are returned normalized in our API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8036852724546562,\n",
       " 0.7973797667134029,\n",
       " 0.6907574075157661,\n",
       " 0.7778821397555651,\n",
       " 0.7731251314563298,\n",
       " 0.7613239566298422,\n",
       " 0.7811087094463756,\n",
       " 0.7380903967660174,\n",
       " 0.7090377977189425,\n",
       " 0.7846978859204605]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothetical_answer_embedding = embeddings(hypothetical_answer)[0]\n",
    "article_embeddings = embeddings(\n",
    "    [\n",
    "        f\"{article['title']} {article['description']} {article['content'][0:100]}\"\n",
    "        for article in articles\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarities = []\n",
    "for article_embedding in article_embeddings:\n",
    "    cosine_similarities.append(dot(hypothetical_answer_embedding, article_embedding))\n",
    "\n",
    "cosine_similarities[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use these similarity scores to sort and filter the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 articles: \n",
      "\n",
      "Title: We eventually want to become a reinsurance broker: Yashish Dahiya, PB Infotech\n",
      "Description: “This year we might be performing a little better than expected, but that is not anything significant right. It is just maybe 5-10% better than expected. So, our guidance stays the same. This year we will broadly be a PAT positive and every year in our core b…\n",
      "Content: Yashish Dahiya, Chairman &amp; CEO, PB Fintech, says we have enough data, which implies that we beli...\n",
      "Score: 0.809970402084174\n",
      "\n",
      "Title: Edgio, Inc. (NASDAQ:EGIO) Q2 2023 Earnings Call Transcript\n",
      "Description: Edgio, Inc. (NASDAQ:EGIO) Q2 2023 Earnings Call Transcript September 12, 2023 Edgio, Inc. misses on earnings expectations. Reported EPS is $-0.12 EPS...\n",
      "Content: Edgio, Inc. (NASDAQ:EGIO) Q2 2023 Earnings Call Transcript September 12, 2023\n",
      "Edgio, Inc. misses on...\n",
      "Score: 0.8036852724546562\n",
      "\n",
      "Title: CIO Talks - Banking and Financial solutions. Fintech. Analytics Miercuri, 20 Septembrie 2023, începand cu orele 14:00\n",
      "Description: Tendințele în industria financiară se îndreaptă spre inovația semnificativ mai mult determinată de tehnologii și colaborare, sau integrare în ecosistemul Fintech si spre o transformare digitală continuă și un rol avansat al AI și al roboticii. &nbsp;\n",
      "Content: Tendinele în industria financiar se îndreapt spre inovaia semnificativ mai mult determinat de tehnol...\n",
      "Score: 0.8004764480768247\n",
      "\n",
      "Title: IBEX Limited (NASDAQ:IBEX) Q4 2023 Earnings Call Transcript\n",
      "Description: IBEX Limited (NASDAQ:IBEX) Q4 2023 Earnings Call Transcript September 13, 2023 IBEX Limited misses on earnings expectations. Reported EPS is $0.33 EPS...\n",
      "Content: IBEX Limited (NASDAQ:IBEX) Q4 2023 Earnings Call Transcript September 13, 2023\n",
      "IBEX Limited misses ...\n",
      "Score: 0.7973797667134029\n",
      "\n",
      "Title: FinTech IPO Index Slides 3% as Affirm and Blend Lead Declining Stocks\n",
      "Description: The FinTech IPO Index gave up nearly 3%, coming into the end of the first full trading week of the fourth quarter. Affirm led declining names, sliding 16% through the past five trading sessions. As reported at the end of last month,  Affirm has partnered with…\n",
      "Content: The FinTech IPO Index gave up nearly 3%, coming into the end of the first full trading week of the f...\n",
      "Score: 0.7941445957333582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scored_articles = zip(articles, cosine_similarities)\n",
    "\n",
    "# Sort articles by cosine similarity\n",
    "sorted_articles = sorted(scored_articles, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print top 5 articles\n",
    "print(\"Top 5 articles:\", \"\\n\")\n",
    "\n",
    "for article, score in sorted_articles[0:5]:\n",
    "    print(\"Title:\", article[\"title\"])\n",
    "    print(\"Description:\", article[\"description\"])\n",
    "    print(\"Content:\", article[\"content\"][0:100] + \"...\")\n",
    "    print(\"Score:\", score)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! These results look a lot more relevant to our original query. Now, let's use the top 5 results to generate a final answer.\n",
    "\n",
    "## 3. Answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the information provided in the question, FinTech Plus had a stellar second quarter (Q2) in 2023. The company reported a revenue of $125 million, which represents a 25% increase year over year. The gross profit margin stood at a solid 58%, thanks to cost efficiencies gained from the scalable business model. Earnings Before Interest, Taxes, Depreciation, and Amortization (EBITDA) surged to $37.5 million, resulting in a remarkable 30% EBITDA margin. Net income for the quarter rose to $16 million, a noteworthy increase from $10 million in Q2 2022.\n",
       "\n",
       "FinTech Plus has experienced substantial growth in its total addressable market by expanding its high yield savings product line and introducing a new RoboAdvisor platform. The company has also diversified its asset-backed securities portfolio by investing heavily in Collateralized Debt Obligations (CDOs) and Residential Mortgage-Backed Securities (RMBS). Additionally, FinTech Plus has invested $25 million in AAA rated corporate bonds to enhance risk-adjusted returns.\n",
       "\n",
       "In terms of financial position, FinTech Plus has total assets of $1.5 billion and total liabilities of $900 million, resulting in a solid equity base of $600 million. The debt-to-equity ratio stands at a healthy figure of 1.5, considering the company's expansionary phase.\n",
       "\n",
       "FinTech Plus has seen substantial organic user growth, with a 15% decrease in Customer Acquisition Cost (CAC) and a 25% increase in Lifetime Value (LTV). The LTV to CAC (LTVCAC) ratio is an impressive 3.5%.\n",
       "\n",
       "The company has implemented a Value at Risk (VaR) model with a 99% confidence level, indicating that the maximum loss will not exceed $5 million in the next trading day. FinTech Plus follows a conservative approach to leverage management and maintains a healthy Tier 1 Capital Ratio of 12.5%.\n",
       "\n",
       "Looking ahead, FinTech Plus forecasts a positive third quarter (Q3) with expected revenue of around $135 million and 8% quarter over quarter growth. This growth will be primarily driven by the company's cutting-edge blockchain solutions and AI-driven predictive analytics. FinTech Plus is also excited about the upcoming Initial Public Offering (IPO) of its subsidiary, Pay Plus, which is expected to raise $200 million, significantly enhancing liquidity and enabling aggressive growth strategies.\n",
       "\n",
       "For more information, you can refer to the following sources:\n",
       "\n",
       "- [We eventually want to become a reinsurance broker: Yashish Dahiya, PB Infotech](https://economictimes.indiatimes.com/markets/expert-view/we-eventually-want-to-become-a-reinsurance-broker-yashish-dahiya-pb-infotech/articleshow/103925028.cms)\n",
       "- [Edgio, Inc. (NASDAQ:EGIO) Q2 2023 Earnings Call Transcript](https://finance.yahoo.com/news/edgio-inc-nasdaq-egio-q2-125307025.html)\n",
       "- [CIO Talks - Banking and Financial solutions. Fintech. Analytics Miercuri, 20 Septembrie 2023, începand cu orele 14:00](https://www.wall-street.ro/articol/Careers/300810/cio-talks-banking-and-financial-solutions-fintech-analytics-miercuri-20-septembrie-2023-incepand-cu-orele-14-00.html)\n",
       "- [IBEX Limited (NASDAQ:IBEX) Q4 2023 Earnings Call Transcript](https://finance.yahoo.com/news/ibex-limited-nasdaq-ibex-q4-120909945.html)\n",
       "- [FinTech IPO Index Slides 3% as Affirm and Blend Lead Declining Stocks](https://www.pymnts.com/news/fintech-investments/2023/fintech-ipo-index-slides-3-pct-affirm-blend-lead-declining-stocks/)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "APIError",
     "evalue": "HTTP code 200 from API (\"{\\\"rate_limit_usage\\\": {\\)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/nghiaph_workspace_115/thesis/.venv/lib/python3.8/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 765\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(rbody)\n\u001b[1;32m    766\u001b[0m \u001b[39mexcept\u001b[39;00m (JSONDecodeError, \u001b[39mUnicodeDecodeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Unterminated string starting at: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb Cell 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     model\u001b[39m=\u001b[39mGPT_MODEL,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     messages\u001b[39m=\u001b[39m[{\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: ANSWER_INPUT}],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     temperature\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m completion:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     text \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m chunk\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdelta\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.166.128.115/home/nghiaph/nghiaph_workspace_115/thesis/Experiment_ASR/Search_with_news_api.ipynb#X25sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     display\u001b[39m.\u001b[39mclear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/nghiaph_workspace_115/thesis/.venv/lib/python3.8/site-packages/openai/api_resources/abstract/engine_api_resource.py:168\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    166\u001b[0m     \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n\u001b[0;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    169\u001b[0m         util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m    170\u001b[0m             line,\n\u001b[1;32m    171\u001b[0m             api_key,\n\u001b[1;32m    172\u001b[0m             api_version,\n\u001b[1;32m    173\u001b[0m             organization,\n\u001b[1;32m    174\u001b[0m             engine\u001b[39m=\u001b[39mengine,\n\u001b[1;32m    175\u001b[0m             plain_old_data\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mplain_old_data,\n\u001b[1;32m    176\u001b[0m         )\n\u001b[1;32m    177\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m response\n\u001b[1;32m    178\u001b[0m     )\n\u001b[1;32m    179\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     obj \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mconvert_to_openai_object(\n\u001b[1;32m    181\u001b[0m         response,\n\u001b[1;32m    182\u001b[0m         api_key,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m         plain_old_data\u001b[39m=\u001b[39m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mplain_old_data,\n\u001b[1;32m    187\u001b[0m     )\n",
      "File \u001b[0;32m~/nghiaph_workspace_115/thesis/.venv/lib/python3.8/site-packages/openai/api_requestor.py:703\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns the response(s) and a bool indicating whether it is a stream.\"\"\"\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[39mif\u001b[39;00m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mtext/event-stream\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Type\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 703\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39;49mstatus_code, result\u001b[39m.\u001b[39;49mheaders, stream\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    710\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    711\u001b[0m             result\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    717\u001b[0m     )\n",
      "File \u001b[0;32m~/nghiaph_workspace_115/thesis/.venv/lib/python3.8/site-packages/openai/api_requestor.py:767\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    765\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(rbody)\n\u001b[1;32m    766\u001b[0m \u001b[39mexcept\u001b[39;00m (JSONDecodeError, \u001b[39mUnicodeDecodeError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 767\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIError(\n\u001b[1;32m    768\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mHTTP code \u001b[39m\u001b[39m{\u001b[39;00mrcode\u001b[39m}\u001b[39;00m\u001b[39m from API (\u001b[39m\u001b[39m{\u001b[39;00mrbody\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m, rbody, rcode, headers\u001b[39m=\u001b[39mrheaders\n\u001b[1;32m    769\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    770\u001b[0m resp \u001b[39m=\u001b[39m OpenAIResponse(data, rheaders)\n\u001b[1;32m    771\u001b[0m \u001b[39m# In the future, we might add a \"status\" parameter to errors\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[39m# to better handle the \"error while streaming\" case.\u001b[39;00m\n",
      "\u001b[0;31mAPIError\u001b[0m: HTTP code 200 from API (\"{\\\"rate_limit_usage\\\": {\\)"
     ]
    }
   ],
   "source": [
    "formatted_top_results = [\n",
    "    {\n",
    "        \"title\": article[\"title\"],\n",
    "        \"description\": article[\"description\"],\n",
    "        \"url\": article[\"url\"],\n",
    "    }\n",
    "    for article, _score in sorted_articles[0:5]\n",
    "]\n",
    "\n",
    "ANSWER_INPUT = f\"\"\"\n",
    "Generate an answer to the user's question based on the given search results. \n",
    "TOP_RESULTS: {formatted_top_results}\n",
    "USER_QUESTION: {USER_QUESTION}\n",
    "\n",
    "Include as much information as possible in the answer. Reference the relevant search result urls as markdown links.\n",
    "\"\"\"\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "    model=GPT_MODEL,\n",
    "    messages=[{\"role\": \"user\", \"content\": ANSWER_INPUT}],\n",
    "    temperature=0.5,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "text = \"\"\n",
    "for chunk in completion:\n",
    "    text += chunk.choices[0].delta.get(\"content\", \"\")\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(display.Markdown(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
